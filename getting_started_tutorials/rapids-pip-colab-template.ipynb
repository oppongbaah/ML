{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "scfLT2i0MLyD"
      },
      "source": [
        "<a target=\"_blank\" href=\"https://colab.research.google.com/github/rapidsai-community/showcase/blob/main/getting_started_tutorials/rapids-pip-colab-template.ipynb\">\n",
        "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Install RAPIDS into Colab\"/>\n",
        "</a>\n",
        "\n",
        "# RAPIDS cuDF is now already on your Colab instance!\n",
        "RAPIDS cuDF is preinstalled on Google Colab and instantly accelerates Pandas with zero code changes. [You can quickly get started with our tutorial notebook](https://nvda.ws/rapids-cudf). This notebook template is for users who want to utilize the full suite of the RAPIDS libraries for their workflows on Colab.  \n",
        "\n",
        "# Environment Sanity Check #\n",
        "\n",
        "Click the _Runtime_ dropdown at the top of the page, then _Change Runtime Type_ and confirm the instance type is _GPU_.\n",
        "\n",
        "You can check the output of `!nvidia-smi` to check which GPU you have.  Please uncomment the cell below if you'd like to do that.  Currently, RAPIDS runs on all available Colab GPU instances."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "67T0090Jk2KL"
      },
      "source": [
        "# !nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U_v33LnDVNo3"
      },
      "source": [
        "#Setup:\n",
        "This set up script:\n",
        "\n",
        "1. Checks to make sure that the GPU is RAPIDS compatible\n",
        "1. Pip Installs the RAPIDS' libraries, which are:\n",
        "  1. cuDF\n",
        "  1. cuML\n",
        "  1. cuGraph\n",
        "  1. cuSpatial\n",
        "  1. cuxFilter\n",
        "  1. cuCIM\n",
        "  1. xgboost\n",
        "\n",
        "# Controlling Which RAPIDS Version is Installed\n",
        "This line in the cell below, `!python rapidsai-csp-utils/colab/pip-install.py`, kicks off the RAPIDS installation script.  You can control the RAPIDS version installed by adding either `latest`, `nightlies` or the default/blank option.  Example:\n",
        "\n",
        "`!python rapidsai-csp-utils/colab/pip-install.py <option>`\n",
        "\n",
        "You can now tell the script to install:\n",
        "1. **RAPIDS + Colab Default Version**, by leaving the install script option blank (or giving an invalid option), adds the rest of the RAPIDS libraries to the RAPIDS cuDF library preinstalled on Colab.  **This is the default and recommended version.**  Example: `!python rapidsai-csp-utils/colab/pip-install.py`\n",
        "1. **Latest known working RAPIDS stable version**, by using the option `latest` upgrades all RAPIDS labraries to the latest working RAPIDS stable version.  Usually early access for future RAPIDS+Colab functionality - some functionality may not work, but can be same as the default version. Example: `!python rapidsai-csp-utils/colab/pip-install.py latest`\n",
        "1. **the current nightlies version**, by using the option, `nightlies`, installs current RAPIDS nightlies version.  For RAPIDS Developer use - **not recommended/untested**.  Example: `!python rapidsai-csp-utils/colab/pip-install.py nightlies`\n",
        "\n",
        "\n",
        "**This will complete in about 5-6 minutes**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B0C8IV5TQnjN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b57f113-c81c-4773-8330-2dbf5fe28666"
      },
      "source": [
        "# This get the RAPIDS-Colab install files and test check your GPU.  Run this and the next cell only.\n",
        "# Please read the output of this cell.  If your Colab Instance is not RAPIDS compatible, it will warn you and give you remediation steps.\n",
        "!git clone https://github.com/rapidsai/rapidsai-csp-utils.git\n",
        "!python rapidsai-csp-utils/colab/pip-install.py\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'rapidsai-csp-utils'...\n",
            "remote: Enumerating objects: 592, done.\u001b[K\n",
            "remote: Counting objects: 100% (158/158), done.\u001b[K\n",
            "remote: Compressing objects: 100% (76/76), done.\u001b[K\n",
            "remote: Total 592 (delta 125), reused 82 (delta 82), pack-reused 434 (from 3)\u001b[K\n",
            "Receiving objects: 100% (592/592), 194.79 KiB | 8.12 MiB/s, done.\n",
            "Resolving deltas: 100% (299/299), done.\n",
            "Installing RAPIDS remaining 25.04 libraries\n",
            "Using Python 3.11.11 environment at: /usr\n",
            "Resolved 160 packages in 926ms\n",
            "Downloading cuspatial-cu12 (4.1MiB)\n",
            "Downloading raft-dask-cu12 (274.9MiB)\n",
            "Downloading pylibcugraph-cu12 (2.0MiB)\n",
            "Downloading rmm-cu12 (1.5MiB)\n",
            "Downloading cudf-cu12 (1.7MiB)\n",
            "Downloading libcudf-cu12 (538.8MiB)\n",
            "Downloading libcugraph-cu12 (1.4GiB)\n",
            "Downloading cugraph-cu12 (3.0MiB)\n",
            "Downloading cucim-cu12 (5.6MiB)\n",
            "Downloading cuml-cu12 (9.4MiB)\n",
            "Downloading librmm-cu12 (2.9MiB)\n",
            "Downloading libcuml-cu12 (404.9MiB)\n",
            "Downloading cuproj-cu12 (1.1MiB)\n",
            "Downloading libcuspatial-cu12 (31.1MiB)\n",
            "Downloading dask (1.3MiB)\n",
            "Downloading datashader (17.5MiB)\n",
            "Downloading libcuvs-cu12 (1.1GiB)\n",
            "Downloading libkvikio-cu12 (2.0MiB)\n",
            "Downloading pylibcudf-cu12 (26.4MiB)\n",
            "Downloading libraft-cu12 (20.8MiB)\n",
            "Downloading ucx-py-cu12 (2.2MiB)\n",
            " Downloaded cuproj-cu12\n",
            " Downloaded rmm-cu12\n",
            " Downloaded datashader\n",
            " Downloaded cudf-cu12\n",
            " Downloaded dask\n",
            " Downloaded pylibcugraph-cu12\n",
            " Downloaded libkvikio-cu12\n",
            " Downloaded ucx-py-cu12\n",
            " Downloaded cugraph-cu12\n",
            " Downloaded librmm-cu12\n",
            " Downloaded cuspatial-cu12\n",
            " Downloaded cucim-cu12\n",
            " Downloaded cuml-cu12\n",
            " Downloaded pylibcudf-cu12\n",
            " Downloaded libcuspatial-cu12\n",
            " Downloaded libraft-cu12\n",
            " Downloaded raft-dask-cu12\n",
            " Downloaded libcudf-cu12\n",
            " Downloaded libcuml-cu12\n",
            " Downloaded libcuvs-cu12\n",
            " Downloaded libcugraph-cu12\n",
            "Prepared 37 packages in 1m 00s\n",
            "Uninstalled 25 packages in 762ms\n",
            "Installed 37 packages in 510ms\n",
            " + cucim-cu12==25.4.0\n",
            " - cudf-cu12==25.2.1 (from https://pypi.nvidia.com/cudf-cu12/cudf_cu12-25.2.1-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl)\n",
            " + cudf-cu12==25.4.0\n",
            " + cugraph-cu12==25.4.0\n",
            " - cuml-cu12==25.2.1\n",
            " + cuml-cu12==25.4.0\n",
            " + cuproj-cu12==25.4.0\n",
            " + cuspatial-cu12==25.4.0\n",
            " - cuvs-cu12==25.2.1\n",
            " + cuvs-cu12==25.4.0\n",
            " + cuxfilter-cu12==25.4.0\n",
            " - dask==2024.12.1\n",
            " + dask==2025.2.0\n",
            " - dask-cuda==25.2.0\n",
            " + dask-cuda==25.4.0\n",
            " - dask-cudf-cu12==25.2.2\n",
            " + dask-cudf-cu12==25.4.0\n",
            " + datashader==0.18.0\n",
            " - distributed==2024.12.1\n",
            " + distributed==2025.2.0\n",
            " - distributed-ucxx-cu12==0.42.0\n",
            " + distributed-ucxx-cu12==0.43.0\n",
            " + jupyter-server-proxy==4.4.0\n",
            " - libcudf-cu12==25.2.1 (from https://pypi.nvidia.com/libcudf-cu12/libcudf_cu12-25.2.1-py3-none-manylinux_2_28_x86_64.whl)\n",
            " + libcudf-cu12==25.4.0\n",
            " - libcugraph-cu12==25.2.0\n",
            " + libcugraph-cu12==25.4.0\n",
            " - libcuml-cu12==25.2.1\n",
            " + libcuml-cu12==25.4.0\n",
            " + libcuspatial-cu12==25.4.0\n",
            " - libcuvs-cu12==25.2.1\n",
            " + libcuvs-cu12==25.4.0\n",
            " - libkvikio-cu12==25.2.1\n",
            " + libkvikio-cu12==25.4.0\n",
            " - libraft-cu12==25.2.0\n",
            " + libraft-cu12==25.4.0\n",
            " + librmm-cu12==25.4.0\n",
            " - libucxx-cu12==0.42.0\n",
            " + libucxx-cu12==0.43.0\n",
            " - numba-cuda==0.2.0\n",
            " + numba-cuda==0.4.0\n",
            " - nx-cugraph-cu12==25.2.0 (from https://pypi.nvidia.com/nx-cugraph-cu12/nx_cugraph_cu12-25.2.0-py3-none-any.whl)\n",
            " + nx-cugraph-cu12==25.4.0\n",
            " + pyct==0.5.0\n",
            " - pylibcudf-cu12==25.2.1 (from https://pypi.nvidia.com/pylibcudf-cu12/pylibcudf_cu12-25.2.1-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl)\n",
            " + pylibcudf-cu12==25.4.0\n",
            " - pylibcugraph-cu12==25.2.0\n",
            " + pylibcugraph-cu12==25.4.0\n",
            " - pylibraft-cu12==25.2.0\n",
            " + pylibraft-cu12==25.4.0\n",
            " - raft-dask-cu12==25.2.0\n",
            " + raft-dask-cu12==25.4.0\n",
            " - rapids-dask-dependency==25.2.0\n",
            " + rapids-dask-dependency==25.4.0\n",
            " + rapids-logger==0.1.1\n",
            " - rmm-cu12==25.2.0\n",
            " + rmm-cu12==25.4.0\n",
            " + simpervisor==1.0.0\n",
            " - ucx-py-cu12==0.42.0\n",
            " + ucx-py-cu12==0.43.0\n",
            " - ucxx-cu12==0.42.0\n",
            " + ucxx-cu12==0.43.0\n",
            "\n",
            "        ***********************************************************************\n",
            "        The pip install of RAPIDS is complete.\n",
            "\n",
            "        Please do not run any further installation from the conda based installation methods, as they may cause issues!\n",
            "\n",
            "        Please ensure that you're pulling from the git repo to remain updated with the latest working install scripts.\n",
            "\n",
            "        Troubleshooting:\n",
            "            - If there is an installation failure, please check back on RAPIDSAI owned templates/notebooks to see how to update your personal files.\n",
            "            - If an installation failure persists when using the latest script, please make an issue on https://github.com/rapidsai-community/rapidsai-csp-utils\n",
            "        ***********************************************************************\n",
            "        \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pZJMJ6BulmMn"
      },
      "source": [
        "# RAPIDS is now installed on Colab.  \n",
        "You can copy your code into the cells below or use the below to validate your RAPIDS installation and version.  \n",
        "# Enjoy!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4nLrk46BllED",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "02a1ef1c-6f49-461e-fc46-89122811cbcf"
      },
      "source": [
        "import cudf\n",
        "cudf.__version__"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'25.02.01'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cuml\n",
        "cuml.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "xgAFgI15ddf6",
        "outputId": "d93c5688-44ea-46b9-cd05-539b9726856a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'25.02.01'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import cugraph\n",
        "# cugraph.__version__"
      ],
      "metadata": {
        "id": "JOCMWaUal1fI"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import cuspatial\n",
        "# cuspatial.__version__"
      ],
      "metadata": {
        "id": "AnmtYjzvVTtv"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import cuxfilter\n",
        "# cuxfilter.__version__"
      ],
      "metadata": {
        "id": "CYjcARDFVWWD"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dlsyk9m9NN2K"
      },
      "source": [
        "# Next Steps #\n",
        "\n",
        "For an overview of how you can access and work with your own datasets in Colab, check out [this guide](https://towardsdatascience.com/3-ways-to-load-csv-files-into-colab-7c14fcbdcb92).\n",
        "\n",
        "For more RAPIDS examples, check out our RAPIDS notebooks repos:\n",
        "1. https://github.com/rapidsai/notebooks\n",
        "2. https://github.com/rapidsai/notebooks-contrib"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import roc_curve, auc, silhouette_score\n",
        "from sklearn.decomposition import PCA\n",
        "# from sklearn.manifold import TSNE\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.cluster import DBSCAN\n",
        "\n",
        "from cuml.manifold import TSNE as cuTSNE\n",
        "import cupy as cp\n",
        "from cuml.manifold import TSNE as cuTSNE\n",
        "from cuml.cluster import DBSCAN as cuDBSCAN\n",
        "\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# print(\"Is CUDA available?\", torch.cuda.is_available())\n",
        "# print(\"Device name:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"No GPU\")"
      ],
      "metadata": {
        "id": "9GE3Jvj8d3_M"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from os import X_OK\n",
        "class Ensemble:\n",
        "    def __init__(self):\n",
        "        self.__df = None     # data on CPU\n",
        "        self.__tensor = None # data on GPU\n",
        "        self.__labels = None\n",
        "        self.__centroids = None\n",
        "        self.__PCA_components = 2\n",
        "        self.X_tsne = None\n",
        "        self.X_pca = None\n",
        "\n",
        "    def __batched_silhouette_score(self, data, labels, batch_size=5000):\n",
        "        n_samples = data.shape[0]\n",
        "        n_batches = (n_samples + batch_size - 1) // batch_size\n",
        "        scores = []\n",
        "\n",
        "        for i in range(n_batches):\n",
        "            start = i * batch_size\n",
        "            end = min((i + 1) * batch_size, n_samples)\n",
        "            data_batch = data[start:end]\n",
        "            labels_batch = labels[start:end]\n",
        "\n",
        "            # Only compute if at least 2 unique labels in batch\n",
        "            if len(np.unique(labels_batch)) > 1:\n",
        "                try:\n",
        "                    score = silhouette_score(data_batch, labels_batch)\n",
        "                    scores.append(score)\n",
        "                except:\n",
        "                    continue\n",
        "\n",
        "        if scores:\n",
        "            return np.mean(scores)\n",
        "        else:\n",
        "            return None\n",
        "\n",
        "    def __tensorfy_data(self, X):\n",
        "        # Convert to PyTorch tensor and move to GPU\n",
        "        data = torch.tensor(X, dtype=torch.float32).cuda()\n",
        "\n",
        "        # Convert to cuDF for RAPIDS\n",
        "        X_cudf = cudf.DataFrame.from_records(X)\n",
        "\n",
        "        self.__tensor = data\n",
        "        return data\n",
        "\n",
        "    def __scale_data(self):\n",
        "        scaler = StandardScaler()\n",
        "        self.__df = scaler.fit_transform(self.__df)\n",
        "        return self\n",
        "\n",
        "    def __drop_features(self, features):\n",
        "        self.__df = self.__df.drop(columns=features, axis=1)\n",
        "        return self\n",
        "\n",
        "    def get_data(self, count=5):\n",
        "        if count == \"*\":\n",
        "            return self.__df\n",
        "\n",
        "        return self.__df.head(count)\n",
        "\n",
        "    def get_labels(self):\n",
        "        return self.__labels\n",
        "\n",
        "    def get_centroids(self):\n",
        "        return self.__centroids\n",
        "\n",
        "    def get_components_count(self):\n",
        "        return self.____PCA_components\n",
        "\n",
        "    def load_data(self, filepath):\n",
        "        df = pd.read_csv(datasource)\n",
        "        self.__df = df\n",
        "\n",
        "    def append_lables(self, title=\"clusters\"):\n",
        "        # bring the labels back to CPU\n",
        "        labels = self.__labels.cpu()\n",
        "        self.__df[title] = labels.numpy()\n",
        "\n",
        "    def export_to_excel(self, filepath):\n",
        "        # Export the new data to excel\n",
        "        self.__df.to_csv(index=False)\n",
        "\n",
        "    def initial_PCA(self, threshold=0.95):\n",
        "        # Fit PCA without reducing dimensionality yet\n",
        "        pca = PCA()\n",
        "\n",
        "        X = self.__drop_features([\"time\"]).__scale_data().get_data(count=\"*\")\n",
        "        print(\"Time is dropped and the rest of the data is scaled: \\n\", X)\n",
        "        pca.fit(X)\n",
        "\n",
        "        # Cumulative explained variance\n",
        "        cumulative_variance = np.cumsum(pca.explained_variance_ratio_)\n",
        "\n",
        "        # add the number of components to the global scope\n",
        "        self.____PCA_components = np.argmax(cumulative_variance >= threshold) + 1\n",
        "\n",
        "        # Plot\n",
        "        plt.figure(figsize=(8, 5))\n",
        "        plt.plot(range(1, len(cumulative_variance) + 1), cumulative_variance, marker='o')\n",
        "        plt.axhline(y=0.95, color='r', linestyle='--', label='95% Variance')\n",
        "        plt.axhline(y=0.99, color='g', linestyle='--', label='99% Variance')\n",
        "        plt.title('Cumulative Explained Variance by PCA Components')\n",
        "        plt.xlabel('Number of Principal Components')\n",
        "        plt.ylabel('Cumulative Explained Variance')\n",
        "        plt.grid(True)\n",
        "        plt.legend()\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    def visualize_PCA(self, title=\"\"):\n",
        "        if self.X_pca is None:\n",
        "            pca = PCA(n_components=self.____PCA_components)\n",
        "            X_pca = pca.fit_transform(self.__df)\n",
        "            self.X_pca = X_pca\n",
        "        else:\n",
        "            X_pca = self.X_pca\n",
        "\n",
        "        plt.figure(figsize=(8,6))\n",
        "        plt.scatter(X_pca[:, 0], X_pca[:, 1], alpha=0.7, edgecolors='k')\n",
        "        plt.xlabel('Primary Voltage (A)')\n",
        "        plt.ylabel('Secondary Voltage (A)')\n",
        "        plt.title(title)\n",
        "        plt.grid(True)\n",
        "        plt.show()\n",
        "\n",
        "    def visualize_TSNE(self, title=\"\"):\n",
        "        if self.X_tsne is None:\n",
        "            tsne = TSNE(\n",
        "                n_components=2,\n",
        "                perplexity=30,\n",
        "                metric=\"euclidean\",\n",
        "                n_jobs=-1,           # multicore speed\n",
        "                random_state=42,\n",
        "                verbose=True\n",
        "            )\n",
        "            X_tsne = tsne.fit_transform(self.__df)\n",
        "            self.X_tsne = X_tsne\n",
        "        else:\n",
        "            X_tsne = self.X_tsne\n",
        "\n",
        "        # Plot\n",
        "        plt.figure(figsize=(8,6))\n",
        "        plt.scatter(X_tsne[:, 0], X_tsne[:, 1], s=10, alpha=0.7)\n",
        "        plt.title(title)\n",
        "        plt.xlabel(\"Dim 1\")\n",
        "        plt.ylabel(\"Dim 2\")\n",
        "        plt.grid(True)\n",
        "        plt.show()\n",
        "\n",
        "    def dbscan(self, eps, min_samples=10):\n",
        "        db = DBSCAN(eps=eps, min_samples=min_samples)\n",
        "        self.__labels = db.fit_predict(self.X_tsn)\n",
        "\n",
        "    def kmeans_torch(self, num_clusters=5, num_iters=100):\n",
        "        X = self.__tensorfy_data(self.X_pca)\n",
        "\n",
        "        N, D = X.shape\n",
        "        # Initialize centroids randomly from the dataset\n",
        "        centroids = X[torch.randperm(N)[:num_clusters]]\n",
        "\n",
        "        for _ in range(num_iters):\n",
        "            # Compute distances and assign clusters\n",
        "            distances = torch.cdist(X, centroids)\n",
        "            labels = torch.argmin(distances, dim=1)\n",
        "\n",
        "            # Update centroids\n",
        "            for k in range(num_clusters):\n",
        "                mask = labels == k\n",
        "                if mask.sum() == 0:\n",
        "                    continue  # Avoid empty cluster\n",
        "                centroids[k] = X[mask].mean(dim=0)\n",
        "\n",
        "        self.__labels = labels\n",
        "        self.__centroids = centroids\n",
        "\n",
        "    def evaluate(self, model_type, batch_size=5000):\n",
        "        data_cpu = self.__tensor.detach().cpu().numpy()  # shape: (N, D)\n",
        "        labels_cpu = self.__labels.detach().cpu().numpy()  # shape: (N,)\n",
        "        sil_score = self.__batched_silhouette_score(data_cpu, labels_cpu, batch_size=5000)\n",
        "        print(f\"Silhouette Score: {sil_score:.3f}\")\n",
        "\n",
        "        if model_type == \"kmeans\":\n",
        "            self.visualize_PCA(\"'K-Means Clusters (PCA projection)'\")\n",
        "        else:\n",
        "            n_clusters = len(set(self.__labels)) - (1 if -1 in self.__labels else 0)\n",
        "            n_noise = list(self.__labels).count(-1)\n",
        "            title = f\"DBSCAN Clustering (eps={eps})\\nClusters: {n_clusters}, Noise: {n_noise}\"\n",
        "            self.visualize_TSNE(title)\n"
      ],
      "metadata": {
        "id": "x73RM5c3bS19"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TOYj8RVMbWO8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}